{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c7ac4a7-c518-40e3-a2c7-54124d1aa60e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading image 1 of 9, (S2B_MSIL2A_20201008T110849_N0214_R137_T30SUH_20201008T140700.SAFE)\n",
      "Attempting to write to file: S2B_MSIL2A_20201008T110849_N0214_R137_T30SUH_20201008T140700.SAFE.zip\n",
      " The image 1 of 9 S2B_MSIL2A_20201008T110849_N0214_R137_T30SUH_20201008T140700.SAFE is downloaded\n",
      " Data extraction from S2B_MSIL2A_20201008T110849_N0214_R137_T30SUH_20201008T140700.SAFE is starting\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Not an ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/shapely/ops.py:276\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(func, geom)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m geom\u001b[38;5;241m.\u001b[39mgeom_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolygon\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 276\u001b[0m     shell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(geom\u001b[38;5;241m.\u001b[39mexterior)(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfunc(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[43mgeom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoords\u001b[49m))))\n\u001b[1;32m    277\u001b[0m     holes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28mtype\u001b[39m(ring)(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfunc(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mring\u001b[38;5;241m.\u001b[39mcoords))))\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ring \u001b[38;5;129;01min\u001b[39;00m geom\u001b[38;5;241m.\u001b[39minteriors\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/shapely/geometry/base.py:223\u001b[0m, in \u001b[0;36mBaseGeometry.coords\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Access to geometry's coordinates (CoordinateSequence)\"\"\"\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m coords_array \u001b[38;5;241m=\u001b[39m \u001b[43mshapely\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_z\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CoordinateSequence(coords_array)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/shapely/coordinates.py:136\u001b[0m, in \u001b[0;36mget_coordinates\u001b[0;34m(geometry, include_z, return_index)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gets coordinates from a geometry array as an array of floats.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03mThe shape of the returned array is (N, 2), with N being the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m([[2.0, 2.0], [4.0, 4.0], [0.0, 0.0]], [0, 0, 1])\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coordinates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobject_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Not an ndarray",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 344\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_list_in, output_list_in2, output_list, processed_items, result_pd, results\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 344\u001b[0m     output_list_in, output_list_in2, output_list, processed_items, result_pd, results \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;66;03m# print(output_list_in, output_list_in2, output_list, processed_items, result_pd, results)\u001b[39;00m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe end of the script\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 331\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    328\u001b[0m csv_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMOR_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m start_date \u001b[38;5;241m+\u001b[39m end_date \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    330\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m--> 331\u001b[0m output_list_in, output_list, processed_items, result_pd, results \u001b[38;5;241m=\u001b[39m \u001b[43mS2processing_frompolygon\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maoi_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maoi_fp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_collection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_pd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m output_list_in2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output_list) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[2], line 299\u001b[0m, in \u001b[0;36mS2processing_frompolygon\u001b[0;34m(start_date, end_date, aoi_download, aoi_fp, results, data_collection, datatype, output_list, result_pd)\u001b[0m\n\u001b[1;32m    297\u001b[0m outpath_t, outcheck_t \u001b[38;5;241m=\u001b[39m check_and_update_path(inputpath)\n\u001b[1;32m    298\u001b[0m cloud_path \u001b[38;5;241m=\u001b[39m create_new_path(outpath_t)\n\u001b[0;32m--> 299\u001b[0m cldprb_points \u001b[38;5;241m=\u001b[39m \u001b[43mget_pixel_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcloud_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maoi_fp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m cldprb_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(cldprb_points) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(cldprb_points)\n\u001b[1;32m    301\u001b[0m result \u001b[38;5;241m=\u001b[39m create_result_dict(outpath_t, url, item, aoi_fp, cldprb_value)\n",
      "Cell \u001b[0;32mIn[2], line 128\u001b[0m, in \u001b[0;36mget_pixel_values\u001b[0;34m(raster_path, aoi_wkt)\u001b[0m\n\u001b[1;32m    126\u001b[0m aoi \u001b[38;5;241m=\u001b[39m wkt\u001b[38;5;241m.\u001b[39mloads(aoi_wkt)\n\u001b[1;32m    127\u001b[0m project \u001b[38;5;241m=\u001b[39m pyproj\u001b[38;5;241m.\u001b[39mTransformer\u001b[38;5;241m.\u001b[39mfrom_crs(pyproj\u001b[38;5;241m.\u001b[39mCRS(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPSG:4326\u001b[39m\u001b[38;5;124m'\u001b[39m), raster_crs, always_xy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mtransform\n\u001b[0;32m--> 128\u001b[0m aoi_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maoi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m geoms \u001b[38;5;241m=\u001b[39m [aoi_transformed]\n\u001b[1;32m    130\u001b[0m mask \u001b[38;5;241m=\u001b[39m geometry_mask(geoms, transform\u001b[38;5;241m=\u001b[39msrc\u001b[38;5;241m.\u001b[39mtransform, invert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, out_shape\u001b[38;5;241m=\u001b[39m(src\u001b[38;5;241m.\u001b[39mheight, src\u001b[38;5;241m.\u001b[39mwidth))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/shapely/ops.py:289\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(func, geom)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(geom)([func(\u001b[38;5;241m*\u001b[39mc) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m geom\u001b[38;5;241m.\u001b[39mcoords])\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m geom\u001b[38;5;241m.\u001b[39mgeom_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolygon\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 289\u001b[0m     shell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(geom\u001b[38;5;241m.\u001b[39mexterior)([func(\u001b[38;5;241m*\u001b[39mc) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgeom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexterior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoords\u001b[49m])\n\u001b[1;32m    290\u001b[0m     holes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;28mtype\u001b[39m(ring)([func(\u001b[38;5;241m*\u001b[39mc) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m ring\u001b[38;5;241m.\u001b[39mcoords])\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m ring \u001b[38;5;129;01min\u001b[39;00m geom\u001b[38;5;241m.\u001b[39minteriors\n\u001b[1;32m    293\u001b[0m     )\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(geom)(shell, holes)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/shapely/geometry/base.py:223\u001b[0m, in \u001b[0;36mBaseGeometry.coords\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcoords\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    222\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Access to geometry's coordinates (CoordinateSequence)\"\"\"\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m     coords_array \u001b[38;5;241m=\u001b[39m \u001b[43mshapely\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_z\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CoordinateSequence(coords_array)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/shapely/coordinates.py:136\u001b[0m, in \u001b[0;36mget_coordinates\u001b[0;34m(geometry, include_z, return_index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_coordinates\u001b[39m(geometry, include_z\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gets coordinates from a geometry array as an array of floats.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    The shape of the returned array is (N, 2), with N being the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    ([[2.0, 2.0], [4.0, 4.0], [0.0, 0.0]], [0, 0, 1])\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coordinates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobject_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Not an ndarray"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct 30 18:30:02 2024\n",
    "\n",
    "@author: pcss\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "from shapely import wkt\n",
    "from shapely.ops import transform\n",
    "from rasterio.features import geometry_mask\n",
    "import rasterio\n",
    "import pyproj\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "def fetch_satellite_data(start_date, end_date, data_collection, aoi):\n",
    "    \"\"\"Fetch satellite data from Copernicus catalogue.\"\"\"\n",
    "    response = requests.get(\n",
    "        f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq '{data_collection}' and OData.CSC.Intersects(area=geography'SRID=4326;{aoi}) and ContentDate/Start gt {start_date}T00:00:00.000Z and ContentDate/Start lt {end_date}T00:00:00.000Z\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        json_data = response.json()\n",
    "        output_list = pd.DataFrame.from_dict(json_data[\"value\"]).head(50).values.tolist()\n",
    "    except KeyError:\n",
    "        print(\"Error: 'value' not found in JSON response.\")\n",
    "        output_list = []\n",
    "    \n",
    "    return output_list\n",
    "\n",
    "def filter_output_list_by_datatype(output_list, datatype):\n",
    "    \"\"\"Filter the output list by datatype.\"\"\"\n",
    "    return [item for item in output_list if 'MSI' + datatype in item[2]]\n",
    "\n",
    "def generate_url(input_string):\n",
    "    \"\"\"Generate a URL based on the provided input string.\"\"\"\n",
    "    return f\"https://zipper.dataspace.copernicus.eu/odata/v1/Products({input_string})/$value\"\n",
    "\n",
    "def get_access_token(username, password):\n",
    "    \"\"\"Get access token for authorization.\"\"\"\n",
    "    data = {\n",
    "        \"client_id\": \"cdse-public\",\n",
    "        \"username\": username,\n",
    "        \"password\": password,\n",
    "        \"grant_type\": \"password\",\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(\n",
    "            \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\",\n",
    "            data=data,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "    except Exception:\n",
    "        raise Exception(\n",
    "            f\"Access token creation failed. Response from the server was: {r.json()}\"\n",
    "        )\n",
    "    return r.json()[\"access_token\"]\n",
    "\n",
    "def download_file(access_token, url, output_name):\n",
    "    \"\"\"Download file using access token and URL.\"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "    response = session.get(url, headers=headers, stream=True)\n",
    "\n",
    "    print(f\"Attempting to write to file: {output_name}\")\n",
    "\n",
    "    try:\n",
    "        with open(output_name, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    file.write(chunk)\n",
    "    except OSError as e:\n",
    "        print(f\"Error writing file: {e}\")\n",
    "\n",
    "def extract_and_remove_zip(zip_path, extract_to):\n",
    "    \"\"\"Extract and remove zip file.\"\"\"\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "            extracted_items = zip_ref.namelist()\n",
    "            root_folder = os.path.commonpath(extracted_items)\n",
    "            extracted_folder = os.path.join(extract_to, root_folder)\n",
    "        \n",
    "        os.remove(zip_path)\n",
    "        return extracted_folder\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def check_and_update_path(inputpath):\n",
    "    \"\"\"Check and update the path to include necessary subdirectories.\"\"\"\n",
    "    outpath = os.path.join(inputpath, \"GRANULE\")\n",
    "    if not os.path.exists(outpath):\n",
    "        return outpath, \"outpath does not exist\"\n",
    "    \n",
    "    subdirs = [d for d in os.listdir(outpath) if os.path.isdir(os.path.join(outpath, d))]\n",
    "    if not subdirs:\n",
    "        return outpath, \"outpath is empty\"\n",
    "    \n",
    "    outpath = os.path.join(outpath, subdirs[0], \"IMG_DATA\")\n",
    "    if not os.path.exists(outpath):\n",
    "        return outpath, \"outpath does not exist\"\n",
    "    \n",
    "    required_dirs = [\"R10m\", \"R20m\", \"R60m\"]\n",
    "    existing_dirs = [d for d in required_dirs if os.path.exists(os.path.join(outpath, d))]\n",
    "    \n",
    "    if not existing_dirs:\n",
    "        return outpath, \"outpath is empty\"\n",
    "    \n",
    "    if len(existing_dirs) == 1:\n",
    "        return outpath, f\"the folder {existing_dirs[0]} is present\"\n",
    "    elif len(existing_dirs) == 2:\n",
    "        return outpath, f\"the folders {existing_dirs[0]} and {existing_dirs[1]} are present\"\n",
    "    else:\n",
    "        return outpath, f\"the folders {existing_dirs[0]}, {existing_dirs[1]} and {existing_dirs[2]} are present\"\n",
    "\n",
    "def get_pixel_values(raster_path, aoi_wkt):\n",
    "    \"\"\"Get pixel values from raster data within the specified AOI.\"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        raster_crs = src.crs\n",
    "        aoi = wkt.loads(aoi_wkt)\n",
    "        project = pyproj.Transformer.from_crs(pyproj.CRS('EPSG:4326'), raster_crs, always_xy=True).transform\n",
    "        aoi_transformed = transform(project, aoi)\n",
    "        geoms = [aoi_transformed]\n",
    "        mask = geometry_mask(geoms, transform=src.transform, invert=True, out_shape=(src.height, src.width))\n",
    "        data = src.read(1)\n",
    "        pixel_values = data[mask]\n",
    "    \n",
    "    return pixel_values\n",
    "\n",
    "def get_pixel_values_with_expansion(raster_path, aoi_wkt, px_dim=10):\n",
    "    \"\"\"Get pixel values from raster data within the specified AOI, expanded by px_dim meters.\"\"\"\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        raster_crs = src.crs\n",
    "        aoi = wkt.loads(aoi_wkt)\n",
    "        project = pyproj.Transformer.from_crs(pyproj.CRS('EPSG:4326'), raster_crs, always_xy=True).transform\n",
    "        aoi_transformed = transform(project, aoi)\n",
    "        expanded_aoi = aoi_transformed.buffer(px_dim)\n",
    "        geoms = [expanded_aoi]\n",
    "        mask = geometry_mask(geoms, transform=src.transform, invert=True, out_shape=(src.height, src.width))\n",
    "        data = src.read(1)\n",
    "        pixel_values = data[mask]\n",
    "    \n",
    "    return pixel_values\n",
    "\n",
    "def create_result_dict(path, url, item, aoi_wkt, cldprb_value):\n",
    "    \"\"\"Create a dictionary with result attributes.\"\"\"\n",
    "    result = {\n",
    "        'ID': item[2],\n",
    "        'link': url,\n",
    "        'aoi': aoi_wkt,\n",
    "        'ac_date': item[5].split('T')[0],\n",
    "        'ac_time': item[5].split('T')[1],\n",
    "        'cloud_prob': cldprb_value\n",
    "    }\n",
    "    return result\n",
    "\n",
    "def add_band_to_result(result, path, aoi_wkt, band='B02', res='R10m'):\n",
    "    \"\"\"Add band information to the result dictionary.\"\"\"\n",
    "    outpath = os.path.join(path, res)\n",
    "    band_file = None\n",
    "\n",
    "    for file in os.listdir(outpath):\n",
    "        if band in file:\n",
    "            band_file = os.path.join(outpath, file)\n",
    "            break\n",
    "\n",
    "    if band_file:\n",
    "        points = get_pixel_values(band_file, aoi_wkt)\n",
    "        if len(points) < 4:\n",
    "            px_dim = int(res[1:-1])\n",
    "            points = get_pixel_values_with_expansion(band_file, aoi_wkt, px_dim)\n",
    "\n",
    "        result[band] = points\n",
    "        result[band + '_av'] = int(sum(points) / len(points))\n",
    "    else:\n",
    "        result[band] = None\n",
    "        result[band + '_av'] = None\n",
    "\n",
    "    return result\n",
    "\n",
    "def create_new_path(img_data_path):\n",
    "    \"\"\"Create a new path based on the IMG_DATA path.\"\"\"\n",
    "    if not img_data_path.endswith('IMG_DATA'):\n",
    "        print(\"The path does not end with 'IMG_DATA'.\")\n",
    "        return None\n",
    "\n",
    "    return img_data_path.replace('IMG_DATA', 'QI_DATA/MSK_CLDPRB_20m.jp2')\n",
    "\n",
    "def s2_band_resolution_list():\n",
    "    \"\"\"Return a list of band and resolution pairs for Sentinel-2.\"\"\"\n",
    "    return [\n",
    "        (\"B01\", \"R60m\"),\n",
    "        (\"B02\", \"R10m\"),\n",
    "        (\"B03\", \"R10m\"),\n",
    "        (\"B04\", \"R10m\"),\n",
    "        (\"B05\", \"R20m\"),\n",
    "        (\"B06\", \"R20m\"),\n",
    "        (\"B07\", \"R20m\"),\n",
    "        (\"B08\", \"R10m\"),\n",
    "        (\"B8A\", \"R20m\"),\n",
    "        (\"B09\", \"R60m\"),\n",
    "        (\"B11\", \"R20m\"),\n",
    "        (\"B12\", \"R20m\"),\n",
    "    ]\n",
    "\n",
    "def dict_to_dataframe(result, existing_df=None):\n",
    "    \"\"\"Convert a dictionary to a DataFrame and merge with an existing DataFrame if provided.\"\"\"\n",
    "    data = {}\n",
    "    for key, value in result.items():\n",
    "        if isinstance(value, (list, tuple)):\n",
    "            data[key] = value\n",
    "        else:\n",
    "            data[key] = [value] * max(len(v) if isinstance(v, (list, tuple)) else 1 for v in result.values())\n",
    "\n",
    "    temp_df = pd.DataFrame(data)\n",
    "    temp_df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "    if existing_df is not None:\n",
    "        existing_df.dropna(axis=1, how='all', inplace=True)\n",
    "        updated_df = pd.concat([existing_df, temp_df], ignore_index=True)\n",
    "    else:\n",
    "        updated_df = temp_df\n",
    "\n",
    "    return updated_df\n",
    "\n",
    "def export_to_csv(df, output_list, filename='output.csv', thd_cloud=50):\n",
    "    \"\"\"Export DataFrame to CSV, filtering by cloud probability threshold.\"\"\"\n",
    "    filename_pd_pkl = filename[:-4] + 'result_pd' + '.pkl'\n",
    "    filename_ol_pkl = filename[:-4] + 'output_list_in' + '.pkl'\n",
    "    df.to_pickle(filename_pd_pkl)\n",
    "    with open(filename_ol_pkl, 'wb') as file:\n",
    "        pickle.dump(output_list, file)\n",
    "    \n",
    "    columns_to_keep = [\n",
    "        'ID', 'link', 'aoi', 'ac_date', 'ac_time', 'cloud_prob',\n",
    "        'B01_av', 'B02_av', 'B03_av', 'B04_av', 'B05_av', 'B06_av',\n",
    "        'B07_av', 'B08_av', 'B8A_av', 'B09_av', 'B11_av', 'B12_av'\n",
    "    ]\n",
    "    \n",
    "    df_filtered = df[df['cloud_prob'] < thd_cloud]\n",
    "    df_to_export = df_filtered[columns_to_keep].copy()\n",
    "    df_to_export.to_csv(filename, index=False)\n",
    "    print(f\"CSV file saved as {filename}\")\n",
    "    \n",
    "def delete_folder(folder_path):\n",
    "    \"\"\"Delete a folder and its contents.\"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"The folder {folder_path} and all its contents have been deleted.\")\n",
    "    else:\n",
    "        print(f\"The folder {folder_path} does not exist.\")\n",
    "    \n",
    "def S2processing_frompolygon(start_date, end_date, aoi_download, aoi_fp, results, data_collection= \"SENTINEL-2\", datatype = 'L2A', output_list=None, result_pd=None):\n",
    "    \"\"\"Process Sentinel-2 data from a polygon.\"\"\"\n",
    "    if output_list is None:\n",
    "        output_list = fetch_satellite_data(start_date, end_date, data_collection, aoi_download)\n",
    "        output_list = filter_output_list_by_datatype(output_list, datatype)\n",
    "        \n",
    "    output_list_in = output_list\n",
    "    access_token = get_access_token(\"miguel.agudo@elecnor.es\", \"C0pernicu5_ScaleAg!\")\n",
    "    processed_items = []\n",
    "\n",
    "    if result_pd is None: \n",
    "        columns = [\n",
    "            'ID', 'link', 'aoi', 'ac_date', 'ac_time', 'cloud_prob', 'B01',\n",
    "            'B01_av','B02', 'B02_av','B03', 'B03_av','B04', 'B04_av','B05', 'B05_av','B06', 'B06_av',\n",
    "            'B07', 'B07_av','B08', 'B08_av','B8A', 'B8A_av','B09', 'B09_av','B11', 'B11_av','B12', 'B12_av'\n",
    "        ]\n",
    "        result_pd = pd.DataFrame(columns=columns)\n",
    "        \n",
    "    s2_resolution_pairs = s2_band_resolution_list()\n",
    "    current_processed = []\n",
    "    n_images = len(output_list)\n",
    "    for idx, item in enumerate(output_list, start=1):\n",
    "        print(f\"Downloading image {idx} of {n_images}, ({item[2]})\")\n",
    "        output_name = item[2] + \".zip\"\n",
    "        url = generate_url(item[1])\n",
    "        download_file(access_token, url, output_name)\n",
    "        print(f\" The image {idx} of {n_images} {item[2]} is downloaded\")\n",
    "        \n",
    "        zip_path = output_name\n",
    "        extract_to = os.getcwd()\n",
    "        extract_folder = extract_and_remove_zip(zip_path, extract_to)\n",
    "        \n",
    "        print(f\" Data extraction from {item[2]} is starting\")\n",
    "        if extract_folder is None:\n",
    "            print(f\"Skipping image {idx} due to extraction error\")\n",
    "            continue\n",
    "        \n",
    "        inputpath = extract_folder\n",
    "        outpath_t, outcheck_t = check_and_update_path(inputpath)\n",
    "        cloud_path = create_new_path(outpath_t)\n",
    "        cldprb_points = get_pixel_values(cloud_path, aoi_fp)\n",
    "        cldprb_value = sum(cldprb_points) / len(cldprb_points)\n",
    "        result = create_result_dict(outpath_t, url, item, aoi_fp, cldprb_value)\n",
    "        \n",
    "        for band, res in s2_resolution_pairs:\n",
    "            result = add_band_to_result(result, outpath_t, aoi_fp, band=band, res=res)\n",
    "        \n",
    "        results.append(result)\n",
    "        temp_df = pd.DataFrame.from_dict([result])\n",
    "        result_pd = pd.concat([result_pd, temp_df], ignore_index=True)\n",
    "        \n",
    "        current_processed.append(item)\n",
    "        \n",
    "        print(f\" The processing of {item[2]} is finished\")\n",
    "        processed_items.extend(current_processed)\n",
    "        delete_folder(inputpath)\n",
    "        output_list = [item for item in output_list if item not in processed_items]\n",
    "    \n",
    "\n",
    "    return output_list_in, output_list, processed_items, result_pd, results\n",
    "        \n",
    "def main():\n",
    "    \"\"\"Main function to execute Sentinel-2 data processing.\"\"\"\n",
    "    start_date = \"2020-09-30\"\n",
    "    end_date = \"2020-10-31\"\n",
    "    data_collection = \"SENTINEL-2\"\n",
    "    aoi_download = \"POLYGON((-4.78305154699348 38.349247670976325, -4.78305154699348 38.37625826438388, -4.752389021711286 38.37625826438388, -4.752389021711286 38.349247670976325, -4.78305154699348 38.349247670976325))'\"    \n",
    "    datatype = 'L2A'\n",
    "    aoi_fp = \"POLYGON((-4.76764154430692 38.3618962903239, -4.76764154430692 38.3621075912977, -4.7673322500241 38.3621075912977, -4.7673322500241 38.3618962903239, -4.76764154430692 38.3618962903239))\"\n",
    "    csv_name = \"MOR_\" + start_date + end_date +'.csv'\n",
    "\n",
    "    results = list()\n",
    "    output_list_in, output_list, processed_items, result_pd, results = S2processing_frompolygon(\n",
    "        start_date, end_date, aoi_download, aoi_fp, results, data_collection=data_collection, datatype=datatype, output_list=None, result_pd=None\n",
    "    )\n",
    "    \n",
    "    output_list_in2 = None\n",
    "    while len(output_list) != 0:\n",
    "        output_list_in2, output_list, processed_items, result_pd, results = S2processing_frompolygon(\n",
    "            start_date, end_date, aoi_download, aoi_fp, results, data_collection=data_collection, datatype=datatype, output_list=output_list, result_pd=result_pd\n",
    "        )\n",
    "    export_to_csv(result_pd, output_list_in ,filename=csv_name, thd_cloud=50)\n",
    "    return output_list_in, output_list_in2, output_list, processed_items, result_pd, results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    output_list_in, output_list_in2, output_list, processed_items, result_pd, results = main()\n",
    "    # print(output_list_in, output_list_in2, output_list, processed_items, result_pd, results)\n",
    "    print(\"The end of the script\")\n",
    "# output_list, processed_items, result_pd = S2processing_frompolygon(start_date, end_date, aoi_download, aoi_fp, data_collection= \"SENTINEL-2\", datatype = 'L2A' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ea80b-ef4f-4986-a962-866268831697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
